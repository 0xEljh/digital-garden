---
title: "Dreambooth Training Optimization"
slug: "dreambooth-optimization"
size: 1
shortDescription: "Halved VRAM requirements for dreambooth training so it can fit 3080s"
link: "https://drawanyone.ai/"
icon: "DreamboothIcon"
categories: ["Deep Learning"]
date: "2022-12-15"
techStack: ["PyTorch", "Hugging Face", "transformers"]
---

Cut dreambooth VRAM requirements in half: 24GB -> 12GB. Turned my client's app profitable.

Dreambooth, a few-shot approach to finetuning imagegen models, required 24GB at the time when taken off the shelf.
For my client, this meant having to rent costly 3090 GPU instances on runpod.

Through quantization and optimisations made to the regularisation step, I got training to fit within 12GB (3080s), which was a 35% cost reduction.
